---
category: news
title: "Meta Debuts AI Language Model, But It's Only for Researchers"
excerpt: "Facebook parent company Meta's LLaMA program can outperform larger AI models including OpenAI's older GPT 3 model, according to the company."
publishedDateTime: 2023-02-24T19:18:00Z
originalUrl: "https://www.pcmag.com/news/meta-debuts-ai-language-model-but-its-only-for-researchers"
webUrl: "https://www.pcmag.com/news/meta-debuts-ai-language-model-but-its-only-for-researchers"
type: article
quality: 67
heat: -1
published: false

provider:
  name: PC Magazine
  domain: pcmag.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/pcmag.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI

images:
  - url: "https://i.pcmag.com/imagery/articles/05MarzpBaDYapcunQMQdCUP-1.fit_lim.size_1200x630.v1677260670.jpg"
    width: 1120
    height: 630
    isCached: true

related:
  - title: "Meta unveils a new large language model that can run on a single GPU [Updated]"
    excerpt: "The LLaMA collection of language models range from 7 billion to 65 billion parameters in size. By comparison, OpenAI's GPT-3 model—the foundational model behind ChatGPT —has 175 billion parameters. Meta trained its LLaMA models using publicly available datasets,"
    publishedDateTime: 2023-02-24T20:02:00Z
    webUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/"
    ampWebUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/"
    cdnAmpWebUrl: "https://arstechnica-com.cdn.ampproject.org/c/s/arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/"
    type: article
    provider:
      name: Ars Technica
      domain: arstechnica.com
    quality: 85
    images:
      - url: "https://cdn.arstechnica.net/wp-content/uploads/2023/02/meta_llm_hero_1-800x450.jpg"
        width: 800
        height: 450
        isCached: true
  - title: "Meta unveils a new large language model that can run on a single GPU"
    excerpt: "Smaller-sized AI models could lead to running ChatGPT-style language assistants ... can reportedly outperform GPT-3 while running on a single GPU. Unlike the data center requirements for GPT-3 derivatives, LLaMA-13B opens the door for ChatGPT-like ..."
    publishedDateTime: 2023-02-24T20:02:00Z
    webUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/"
    ampWebUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/"
    cdnAmpWebUrl: "https://arstechnica-com.cdn.ampproject.org/c/s/arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/"
    type: article
    provider:
      name: Ars Technica
      domain: arstechnica.com
    quality: 69
  - title: "Meta Released LLaMA, an Open Large Language Model with 65-Billion-Parameters"
    excerpt: "It’s part of Meta’s commitment to open science.” “Training smaller foundation models like LLaMA is desirable in the large language model space because it requires far less computing power and resources to test new approaches,"
    publishedDateTime: 2023-02-24T21:03:00Z
    webUrl: "https://iblnews.org/meta-released-llama-an-open-large-language-model-with-65-billion-parameters/"
    type: article
    provider:
      name: IBL News
      domain: iblnews.org
    quality: 1

secured: "GcRKbM4mRifhWhxmQ9Y3j1fkumwUOcLSUZoVYT3viHjWHjwB8agjxDYfKbhr9N4KYGNWSfNDReqhPyRKrGQwxskhqQSIBDv2NLhz/XCL/VGbQPM1xwCZ8pMSYoY3+tlhCPYQY2VQvK2KPa0kmW2OPVp/CWHUNFzdclCunb9JskZkaJp5qQZhmrAyH/s6LMLihpGU5gyYY+dtIoGPLBoncYfs7nA72leSq7CUkPS8Tq5Vq4aY6OtWeL0tlWniLWON/7Ti+ZQfRr7cC6uV7xEz7Ls4zRoQmJupgzWfN2fCRUPPDi4kHV7bJfRNcidOAHBFoYoEYLMvWga0kUNeRAHAv/uotZgCr6PBnH/xgAh24sna6J9COhxIJbvA8N9oPelw7VOKMV4RSy4uTN16gv9ryqRzV5BFcFqq/24b+31V10A5+00ptcNA/I8mn/UBw4KwKRYXHmJKgJd9CGYWtS6xb24DVCIRvZ434g8Dcy23DAMb2AkJF9ysgUEGSqA7Ngv/XoBvj7fP2qb5WlCT9ePshg==;9JJnl69XiFKrVcqsnPjIiw=="
---


---
category: news
title: "MPNet combines strengths of masked and permuted language modeling for language understanding"
excerpt: "Pretrained language models have been a hot research topic in natural language processing. These models, such as BERT, are usually pretrained on large-scale language corpora with carefully designed pretraining objectives and then fine-tuned on downstream tasks to boost the accuracy."
publishedDateTime: 2020-12-09T19:22:00Z
originalUrl: "https://www.microsoft.com/en-us/research/blog/mpnet-combines-strengths-of-masked-and-permuted-language-modeling-for-language-understanding/"
webUrl: "https://www.microsoft.com/en-us/research/blog/mpnet-combines-strengths-of-masked-and-permuted-language-modeling-for-language-understanding/"
type: article
quality: 13
heat: 13
published: false

provider:
  name: Microsoft
  domain: microsoft.com
  images:
    - url: "https://smartableai.github.io/artificial-intelligence/assets/images/organizations/microsoft.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - Natural Language Processing
  - AI

images:
  - url: "https://www.microsoft.com/en-us/research/uploads/prod/2020/12/1400x788_mpnet_no_logo_still-scaled.jpg"
    width: 2560
    height: 1442
    isCached: true

secured: "q2+E5qiRJoq46K8lq9D8XeDFunOgCpud2LS/MuMUHFz2R46s4EUccg8scn4yLkk1+jLp3Nr+TTUDTdVUwJgQv4xFGCGzyOUyFIU6TQlgVKt62BNPlWBt01uxxQfdnn8uqR5UeK+EYuyp9PMHIrXILU7PYP7ybOnGw/xoETLifVkHm4UoOwN5weODqK5thoTP1MsCiusrpC1jJ/O4HQhX6KLKcdcWinU8aZnU7to3sjemXWEhUGsY2c6cn+ib9Ij8da6Fs3YdoWjFdMsunzBp7n+xFoVGhnuSnioLRB19W6Dlx9XmOUi95QikIZKHtM1VPlBP2HikTHl3RRnnRhE7jDjCEdd9yl6kziXTq1NmXh6ezPq1H4QsAHXky3EP3NS6Fq2R/idc9mMop47hfM8fSKfpDnlGBJ66bq/dyDAq8mX0ZrCuIBnFIfq/YRAEQK1fmVYGQZPu8qY81ogZi1tgA9oxpq2M8bnT4Zk0zn1SBiqAjCQM92khphugKuf2HEal1SOL86+i5C4EcqF0sxjRSA==;SHR/bFJvpbcvvId0taEPXA=="
---


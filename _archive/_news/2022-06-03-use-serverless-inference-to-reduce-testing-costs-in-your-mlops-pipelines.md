---
category: news
title: "Use Serverless Inference to reduce testing costs in your MLOps pipelines"
excerpt: "Amazon SageMaker Serverless Inference is an inference option that enables you to easily deploy machine learning (ML) models for inference without having to configure or manage the underlying infrastructure.&nbsp;SageMaker Serverless Inference is ideal for applications with intermittent or unpredictable"
publishedDateTime: 2022-06-03T16:52:31Z
originalUrl: "https://aws.amazon.com/blogs/machine-learning/use-serverless-inference-to-reduce-testing-costs-in-your-mlops-pipelines/"
webUrl: "https://aws.amazon.com/blogs/machine-learning/use-serverless-inference-to-reduce-testing-costs-in-your-mlops-pipelines/"
type: article
quality: 73
heat: 73
published: true

provider:
  name: AWS
  domain: aws.amazon.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/aws.amazon.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI
  - AWS AI

images:
  - url: "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/06/03/use-serverless-inference.jpg"
    width: 1000
    height: 500
    isCached: true

secured: "gjxDVo1hahjYjAChE3d99rhb3qbIZchyse8PUn8PV8+j1JFqzuLs/z8M1s0/adu7D4jLCWOZF52+VkZgFaA3aAYeKfbevUn9wtN1wamtEKCusUeYXYc6rbWjno6F1k9hRYAIclGUzpLcq37lX1/1rXwp/tb2nRdQXuCuzea6Z7GR2lCcdCZIcQ98OVDUAQ+KydsdGtQ3kFWm9FlWENGWPiAH5bEKThk/04Mjtg3EQ7gOedBT43LbWzd+s+S/rjD6lpFnQYVc/MOwkuYKOh8IC5AI07N9xxAUTgBRkM+VYo/tJ9MallbngRB2c8yiOhyjV60V9yZYhn5nMPvsTgnTJo/bLBs8zXm5uLcRZZ0NcQ4=;Xt664fXevKm7gWwurhlSuA=="
---


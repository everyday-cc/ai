---
category: news
title: "Model inference using TensorFlow and TensorRT"
excerpt: "NVIDIA TensorRT is a high-performance inference optimizer and runtime that delivers low latency and high-throughput for deep learning inference applications. The following notebook demonstrates our recommended inference workflow."
publishedDateTime: 2020-06-21T04:56:00Z
webUrl: "https://docs.microsoft.com/en-us/azure/databricks/applications/deep-learning/inference/resnet-model-inference-tensorrt"
type: article

provider:
  name: Microsoft
  domain: microsoft.com
  images:
    - url: "https://smartableai.github.io/artificial-intelligence/assets/images/organizations/microsoft.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - Google AI
  - AI
  - TensorFlow

images:
  - url: "https://docs.microsoft.com/en-us/media/logos/logo-ms-social.png"
    width: 400
    height: 400
    isCached: true
    title: "Model inference using TensorFlow and TensorRT"

secured: "d8ARpX4BK268cVnwle9ueBn7Axsv24ez5GvBden5wb4pG9KRxX6WmoVAU0mS0F02lbx0ovKVBdZN81iuzaV/enq8HtYU4+FGkz7JN5TktjK86FzqqkVYoG6HkctRHR6+Vm9j7RhE4w5WfXnlLw5/hn0VJCD7Eya3bxm6vjZBJ8+4VJJSo74XqSy2XGIuov2rlnD4BWSB6vVTCe5RnBL2KIdfwAkEwYpgvtMsWDroo7jW4gUNYNhbnIbEe+x2DbgJ/hfVFDbDUUFH3DzRHVvB1auhDE8c8dG/HIVByvj1na/yipNkSn/fAsJt0Im2HK3fC+P5jfLTU8C4NI3PQlZr9g==;SclURtxuuBqS5YuhQaXwKA=="
---


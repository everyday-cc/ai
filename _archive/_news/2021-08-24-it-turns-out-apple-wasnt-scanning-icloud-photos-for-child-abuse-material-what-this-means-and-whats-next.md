---
category: news
title: "It Turns Out Apple Wasn’t Scanning iCloud Photos for Child Abuse Material | What This Means and What’s Next"
excerpt: "Controversy continues to rage on over Apple’s recent announcement of its plans to implement a new Child Sexual Abuse Material (CSAM) Detection system in"
publishedDateTime: 2021-08-23T21:32:00Z
originalUrl: "https://www.idropnews.com/news/it-turns-out-apple-wasnt-previously-scanning-icloud-photos-for-csam-only-icloud-mail/166129/"
webUrl: "https://www.idropnews.com/news/it-turns-out-apple-wasnt-previously-scanning-icloud-photos-for-csam-only-icloud-mail/166129/"
ampWebUrl: "https://www.idropnews.com/news/it-turns-out-apple-wasnt-previously-scanning-icloud-photos-for-csam-only-icloud-mail/166129/amp/"
cdnAmpWebUrl: "https://www-idropnews-com.cdn.ampproject.org/c/s/www.idropnews.com/news/it-turns-out-apple-wasnt-previously-scanning-icloud-photos-for-csam-only-icloud-mail/166129/amp/"
type: article
quality: 26
heat: 26
published: false

provider:
  name: iDrop News
  domain: idropnews.com

topics:
  - Computer Vision
  - AI

images:
  - url: "https://cdn.idropnews.com/wp-content/uploads/2021/08/23143243/Man-Using-a-Photos-App-on-iPhone.jpg"
    width: 1000
    height: 600
    isCached: true

secured: "ahNDhyt7Q9KM7+yxAWyogWFU0cgEjkLU1MfqPMaJpPLemjaKO/+4Eb+KUd1N57cUvjn8pdnM9ZoStGq5LdEUMIihHlfrdVv9VJwM2M98rJs3AY49egZtHLYC2JSSZPW9T8okMJ8lQDIhn3CfcxGX64ysPWu2CyfAVr25GJnRQbQ8SCgrEH31O3JIxP5PtRmjY6hwrsbj3RB9EFNwrODE6Mfb9/fsEf/kHVIQHM6n0Sa1zpQOOsBbxopeRWDbOH5bAKSPQWxZO+xMG2S8BqzZVX7KDbdZo2NYe7OGtSEXlKczZepO4Qos8m/giBXxnt5VWeKWJ7SsmSoIUVRVKBhMXGSOVUengI4vttVzbXW3XxFf4dTVQiCwBRbBFFGQho4KDkWn1LzwMijwAq8utFr3z9RqwQHkW7yZCqY0TQjM8wfGn3AZOygnyyLOVJ/rZHk4LlJ8xyjNnvPKhxheFe9qwIlGnGInymfALlwqMIDReUKO1DEDdYFPShBB1O3f/AaW2g6/6moTlhR/mhjFbxnElg==;YseUuDW8t+TP1o4QGm8Y+g=="
---


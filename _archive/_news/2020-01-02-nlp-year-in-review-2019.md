---
category: news
title: "NLP Year in Review — 2019"
excerpt: "Researchers from Facebook AI also recently published a method based on an all-attention layer for improving the efficiency of a Transformer language model. More work from this research group ..."
publishedDateTime: 2020-01-02T13:10:00Z
webUrl: "https://medium.com/dair-ai/nlp-year-in-review-2019-fb8d523bcb19"
type: article
quality: 54
heat: 54
published: false

provider:
  name: Medium
  domain: medium.com
  images:
    - url: "/assets/images/organizations/medium.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI
  - Facebook AI

images:
  - url: "https://miro.medium.com/max/1200/1*T08rCNctBW5zUvol0gfIig.png"
    width: 1200
    height: 764
    title: "NLP Year in Review — 2019"

secured: "gkOJjX0SudsG4Tmft8HGAnx3vQDH4WIiQOUD22RBrm2NVvSQyH9L7wEvTGveTACwhFa+c0kZ+xXB6Wtmd6xnCjllewNW4MwaAud6GUtAVP3aS/laREzppIfH/+64whThGICsG11UKb0la7hLe0zKgCC5sTzjCgyBqrGAbJz46mQcKG6PECQ0w14l4Go5Fpn0ZWQdMR0yQmXa4ZMBgDnuT6tftC+vpPfEsmB4HIKg8Eubfyw2SPgSbogRGaGho6ANgha9kWTWMud8UAv5lGKhqyB1AjURrnfSpE7grD97k0h1UPfEiGzxeXCWxEMBRUSb;wcoDWKbImSbWW6dPJF4Uag=="
---


---
category: news
title: "EleutherAI Open-Sources Six Billion Parameter GPT-3 Clone GPT-J"
excerpt: "J, a six-billion parameter natural language processing (NLP) AI model based on GPT-3. The model was trained on an 800GB open-source text dataset and has performance comparable to a GPT-3 model of similar size."
publishedDateTime: 2021-07-13T13:20:00Z
originalUrl: "https://www.infoq.com/news/2021/07/eleutherai-gpt-j/"
webUrl: "https://www.infoq.com/news/2021/07/eleutherai-gpt-j/"
type: article
quality: 39
heat: 39
published: false

provider:
  name: InfoQ
  domain: infoq.com

topics:
  - Natural Language Processing
  - AI

images:
  - url: "https://res.infoq.com/news/2021/07/eleutherai-gpt-j/en/headerimage/eleutherai-gpt-j-header-1625512709562.jpg"
    width: 1200
    height: 630
    isCached: true

secured: "FhzESmKQxQK5pv4SRS6FhHaNeCuLnRXgXkDTBl3KTvxgXVIv2l0e7nW5S8/I0ZI8NDCnf9XSl1bfBE1UNUC9/nBmmM08jUS4jFgoWMv01+IpGwKzejxvzsC2hQDmbt444oxtKet0oyljJlWMoY178Q7MR/7dajyI0znZY5H148eFPtc4t0Fk+ReIFq9D0MtNzJgpGt1yyT0A8tldadOQEy2jgLSXiSzt0VSoJVv49O4orrBUBMmUrUUZqP+jJGISFUeEuSKiZ9u1AzgjZwE8+i+Doqtu6r8cC9HZlwSNZEb8XjPOqbHd3Mn2eKMOTrP2JZE0UsrFQpeFkeJQiDhwupcDZhk+EPznAwDbvC/FpVU=;oLOzd9rmEordXfw1qMY7qQ=="
---


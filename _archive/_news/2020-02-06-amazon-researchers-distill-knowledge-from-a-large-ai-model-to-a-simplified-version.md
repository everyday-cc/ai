---
category: news
title: "Amazon researchers distill knowledge from a large AI model to a simplified version"
excerpt: "In AI and machine learning systems, knowledge is typically distilled by training a small model — a student — to mimic a large and cumbersome model — a teacher. The idea is to compress the teacher’s knowledge by using its outputs as labels to optimize the student, but there’s no guarantee knowledge will be transferred to the student ..."
publishedDateTime: 2020-02-06T18:20:00Z
webUrl: "https://venturebeat.com/2020/02/06/amazon-researchers-technique-distills-knowledge-from-a-large-ai-model-to-a-simplified-version-of-it/"
ampWebUrl: "https://venturebeat.com/2020/02/06/amazon-researchers-technique-distills-knowledge-from-a-large-ai-model-to-a-simplified-version-of-it/amp/"
cdnAmpWebUrl: "https://venturebeat-com.cdn.ampproject.org/c/s/venturebeat.com/2020/02/06/amazon-researchers-technique-distills-knowledge-from-a-large-ai-model-to-a-simplified-version-of-it/amp/"
type: article
quality: 81
heat: 81
published: true

provider:
  name: VentureBeat
  domain: venturebeat.com
  images:
    - url: "/assets/images/organizations/venturebeat.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI

images:
  - url: "https://venturebeat.com/wp-content/uploads/2019/12/amazon-logo-reuters.jpg?fit=1200%2C600&strip=all"
    width: 1200
    height: 600
    title: "Amazon researchers distill knowledge from a large AI model to a simplified version"

secured: "oZBnN8buxpfZW8z7avjp4MPuFTKcSEvI3qNFv8jJ7nL6D0Y14xUEkHPqYWvnizjHtsYJLY9CAVILnLguvGQf4+S4gf0A36fmVo/orMVBQwNyO1iBMu4Xs4JA8oAQFOJXtzJCPQpKEi+fq+dngbw6gax0ybFxgZh4moyxazSZTZQwz4sLBgHOKX0J0VdZ57tGum54b1meg3L7gwuMr1AduGWTBCOEuG+dsplKSbaYqmsfowRk8JwCxNwRf41V0Tv3KezZgqg8ZxQRCHxe5oCk26EO48pjOJzYIpxU3OHEpBfFwEuJWRbPnqgOQ2K37TXqu1rDoEjAMaOov61Ql3p/9FPOrWnlfp062yLvmSLMWnfp92oRiGhK9XrJXSROi0G1hluOrD/dg2z2jDTELMmesuF1W+jVJm1eyn5bIXANCli0kLJkUg5VamxpZ54ZBOBukc+cG2lx9J19bW8o841+ylGAJjZGzvP0Bp+sODl5E+c=;pXAMTRErEGTjOjepTzNKEg=="
---


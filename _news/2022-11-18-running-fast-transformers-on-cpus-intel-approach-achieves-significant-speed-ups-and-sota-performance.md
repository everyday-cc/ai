---
category: news
title: "Running Fast Transformers on CPUs: Intel Approach Achieves Significant Speed Ups and SOTA Performance"
excerpt: "Large transformer language models (LM) that scale up to billions of parameters have demonstrated state-of-the-art performance across a wide variety of natural language processing (NLP) tasks. The real-world deployment of such models however remains limited ..."
publishedDateTime: 2022-11-18T01:40:00Z
originalUrl: "https://syncedreview.com/2022/11/17/running-fast-transformers-on-cpus-intel-approach-achieves-significant-speed-ups-and-sota-performance/"
webUrl: "https://syncedreview.com/2022/11/17/running-fast-transformers-on-cpus-intel-approach-achieves-significant-speed-ups-and-sota-performance/"
ampWebUrl: "https://syncedreview.com/2022/11/17/running-fast-transformers-on-cpus-intel-approach-achieves-significant-speed-ups-and-sota-performance/amp/"
cdnAmpWebUrl: "https://syncedreview-com.cdn.ampproject.org/c/s/syncedreview.com/2022/11/17/running-fast-transformers-on-cpus-intel-approach-achieves-significant-speed-ups-and-sota-performance/amp/"
type: article
quality: 29
heat: 29
published: false

provider:
  name: syncedreview
  domain: syncedreview.com

topics:
  - Natural Language Processing
  - AI

images:
  - url: "https://i0.wp.com/syncedreview.com/wp-content/uploads/2022/11/image-51.png?fit=768%2C512&ssl=1"
    width: 768
    height: 512
    isCached: true

secured: "6Tmq4yBOJzWSbh3CEUPLkehJzFyA3mIxW91MawOcn7kWxiEtE7iHGiozzNqXYaquhg7T6SvVbPlxtRj5RjJKpGRoJQB1gNu+Gq+Ef5vBslPEYO3Bj4AI+Y6j6tVYjTRBb3yrPmLxxIiBfojCO/zVVXSwLyMF1slG6r+FJmrYof+7edlY8LrDldnuKXI+Z0MWW5rEZIuwl52Sh2o/rAw+WiUWye1Bd6UFGZUwddeLR5j/l2HhlMDRCZsroKtzEvcbGNSoMWqR1/TzUJ44up9zdcmInH8M7YPxvYNTDcNiLDb8t5qxQ6Fvf61dRiEdt7lVZLSCs8XYkH997yFojmQYQBiAgeUJ/kLZRNSFXDq2OGmIPr6OMYoYY4OAlAn46Y+qhwsRphgwIRtaV6kBTKm7umNS2COVYWqeLsVxEjaLGMaPe95JfRw7CDiDPQ91j+5+cQ2MlaXJZ6ZYqsO/nnB57XbAx+Tll+RUPlq65m1T9jbpK/ItcQOqSnXHcmcwMX46I85550+ScOlO2+sPwly+0w==;1wrWWA3O83e4B91NfOp9EQ=="
---


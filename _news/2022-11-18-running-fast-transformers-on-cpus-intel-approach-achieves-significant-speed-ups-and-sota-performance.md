---
category: news
title: "Running Fast Transformers on CPUs: Intel Approach Achieves Significant Speed Ups and SOTA Performance"
excerpt: "Large transformer language models (LM) that scale up to billions of parameters have demonstrated state-of-the-art performance across a wide variety of natural language processing (NLP) tasks. The real-world deployment of such models however remains limited ..."
publishedDateTime: 2022-11-18T01:40:00Z
originalUrl: "https://syncedreview.com/2022/11/17/running-fast-transformers-on-cpus-intel-approach-achieves-significant-speed-ups-and-sota-performance/"
webUrl: "https://syncedreview.com/2022/11/17/running-fast-transformers-on-cpus-intel-approach-achieves-significant-speed-ups-and-sota-performance/"
ampWebUrl: "https://syncedreview.com/2022/11/17/running-fast-transformers-on-cpus-intel-approach-achieves-significant-speed-ups-and-sota-performance/amp/"
cdnAmpWebUrl: "https://syncedreview-com.cdn.ampproject.org/c/s/syncedreview.com/2022/11/17/running-fast-transformers-on-cpus-intel-approach-achieves-significant-speed-ups-and-sota-performance/amp/"
type: article
quality: 29
heat: 29
published: false

provider:
  name: syncedreview
  domain: syncedreview.com

topics:
  - Natural Language Processing
  - AI

images:
  - url: "https://i0.wp.com/syncedreview.com/wp-content/uploads/2022/11/image-51.png?fit=768%2C512&ssl=1"
    width: 768
    height: 512
    isCached: true

secured: "9FSBcfGdM2Ixb7CUs9UKEVdZfJA4s2gKjNOwhNk/rn4QFnNru6bWNks3b4IsthNCgFs8byL63LA+zDnmBx7BLt6C2mKK6FNENRa98XQ/kK4RzwKAoFaQaDJvy/6zYmrzHJ7NTcm/t9ZtSw7VXbjGSuLIqtf4ExAMF5vgxYyQ2QrX9qnO10nWN/V+3Z0mqmB6kvEBC5V+osqvheW7IH1bfGrqpGUYimDGw+g2aHGHWVtDxvp4nim3M2aGCDvmhI/OWcTTeBrOAC35tjs2hCQgJ0Zlc04crOM49BtqskTkB23/QSfE2fMZpc2m/F6/zxWQ01KF5qZS3iF6GRakC2CUCi6CMEYELHlS74hCeYVc5nM=;+WjsBSOeMwCJ+HN3RYJGWQ=="
---


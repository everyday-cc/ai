---
category: news
title: "Meta unveils a new large language model that can run on a single GPU"
excerpt: "Smaller-sized AI models could lead to running ChatGPT-style language assistants ... can reportedly outperform GPT-3 while running on a single GPU. Unlike the data center requirements for GPT-3 derivatives, LLaMA-13B opens the door for ChatGPT-like ..."
publishedDateTime: 2023-02-24T20:02:00Z
originalUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/"
webUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/"
ampWebUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/"
cdnAmpWebUrl: "https://arstechnica-com.cdn.ampproject.org/c/s/arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/"
type: article
quality: 69
heat: -1
published: false

provider:
  name: Ars Technica
  domain: arstechnica.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/arstechnica.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI Hardware
  - AI

related:
  - title: "Meta unveils a new large language model that can run on a single GPU [Updated]"
    excerpt: "The LLaMA collection of language models range from 7 billion to 65 billion parameters in size. By comparison, OpenAI's GPT-3 model—the foundational model behind ChatGPT —has 175 billion parameters. Meta trained its LLaMA models using publicly available datasets,"
    publishedDateTime: 2023-02-24T20:02:00Z
    webUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/"
    ampWebUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/"
    cdnAmpWebUrl: "https://arstechnica-com.cdn.ampproject.org/c/s/arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/amp/"
    type: article
    provider:
      name: Ars Technica
      domain: arstechnica.com
    quality: 85
    images:
      - url: "https://cdn.arstechnica.net/wp-content/uploads/2023/02/meta_llm_hero_1-800x450.jpg"
        width: 800
        height: 450
        isCached: true
  - title: "Meta Debuts AI Language Model, But It's Only for Researchers"
    excerpt: "Facebook parent company Meta's LLaMA program can outperform larger AI models including OpenAI's older GPT 3 model, according to the company."
    publishedDateTime: 2023-02-24T19:18:00Z
    webUrl: "https://www.pcmag.com/news/meta-debuts-ai-language-model-but-its-only-for-researchers"
    type: article
    provider:
      name: PC Magazine
      domain: pcmag.com
    quality: 67
    images:
      - url: "https://i.pcmag.com/imagery/articles/05MarzpBaDYapcunQMQdCUP-1.fit_lim.size_1200x630.v1677260670.jpg"
        width: 1120
        height: 630
        isCached: true
  - title: "ChatGPT on your PC? Meta unveils new AI model that can run on a single GPU"
    excerpt: "Smaller-sized AI models could lead to running ChatGPT-style language assistants ... can reportedly outperform GPT-3 while running on a single GPU. Unlike the data center requirements for GPT-3 derivatives, LLaMA-13B opens the door for ChatGPT-like ..."
    publishedDateTime: 2023-02-24T20:02:00Z
    webUrl: "https://arstechnica.com/information-technology/2023/02/chatgpt-on-your-pc-meta-unveils-new-ai-model-that-can-run-on-a-single-gpu/"
    type: article
    provider:
      name: Ars Technica
      domain: arstechnica.com
    quality: 62
  - title: "Meta Released LLaMA, an Open Large Language Model with 65-Billion-Parameters"
    excerpt: "It’s part of Meta’s commitment to open science.” “Training smaller foundation models like LLaMA is desirable in the large language model space because it requires far less computing power and resources to test new approaches,"
    publishedDateTime: 2023-02-24T21:03:00Z
    webUrl: "https://iblnews.org/meta-released-llama-an-open-large-language-model-with-65-billion-parameters/"
    type: article
    provider:
      name: IBL News
      domain: iblnews.org
    quality: 1

secured: "zdDbXQb95H7nHpV8bEmNYv6C3AxN9Ku0RdzgC5HyfXAc3AJLCaqcqJen0MjzRmM4C18DYKPJLHsenTofWtNCKHYScL6s/i6dlIe6DnZ1BXV5CF1svy+1hS8vEis+xepshkIxEqAo1yGkfyL4U4yxndmML40VOMLZ3yJCAv/BERqaksM60GHSMm7TDx1In771kjlHsYQICp3V2kXQ988No65sykCl1SbtS8VkYq4nCtqdp2gFznp0M6tig+cJMl7QDjDzgUGjDY7E+Q5GvQRH2BUBIYmrNVlJaDcFt8foIOn673FBmi0aqvNk2RTxOJ8yEh28n5yL0/uQBH3OwEgNDjlaIk2tNcFiEeOezOGT+kRuEl9vPRw86rjREmHTVFXoIm29+osu1lXfFD22BLi5qfnudsaXnmD9ar5ihG7hHn6p7arvU5yh/8iKTOqvEtEYwtYx3l6BNKsVSOucWUq7XdOm1+wwjKgqR85p1Zcy2R3Ezw81KpSPYu1ViHPNELW32fZV6JSRhT92cA5JR3lICQ==;aS5Q4fxYJyjg+Um9for1MQ=="
---


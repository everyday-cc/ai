---
category: news
title: "Large Language Models hallucinate: Here's what you need to know"
excerpt: "Hallucinations are a significant ethical concern associated with LLMs. They occur when the model generates outputs that are grammatically and logically correct but are disconnected from reality, often based on false assumptions."
publishedDateTime: 2023-06-19T09:36:00Z
originalUrl: "https://www.moneycontrol.com/news/business/large-language-models-hallucinate-heres-what-you-need-to-know-10819971.html"
webUrl: "https://www.moneycontrol.com/news/business/large-language-models-hallucinate-heres-what-you-need-to-know-10819971.html"
ampWebUrl: "https://www.moneycontrol.com/news/business/large-language-models-hallucinate-heres-what-you-need-to-know-10819971.html/amp"
cdnAmpWebUrl: "https://www-moneycontrol-com.cdn.ampproject.org/c/s/www.moneycontrol.com/news/business/large-language-models-hallucinate-heres-what-you-need-to-know-10819971.html/amp"
type: article
quality: 44
heat: 44
published: false

provider:
  name: moneycontrol.com
  domain: moneycontrol.com

topics:
  - Natural Language Processing
  - AI

images:
  - url: "https://images.moneycontrol.com/static-mcnews/2023/06/AI.jpg"
    width: 768
    height: 429
    isCached: true

secured: "UtqOWnK+b+XF7fNcSmnxkxfld9X71OTkoNmQxPqrmNwpjVuUWdJ2wVA7FPQNCCde2nhxGTlLxijc/bmQN5c3VlpR6xyDjMV93L5QzKQ/rUukXOtzMAA6Mtf2y42dMPxzn+sZK2fwOWoLKmSeCOfXnu+/Bwk8Nqoklu4MM2ujviNpAXQINuEzMP2EvnFTJRG2DA8znEgbxud01RhHh9IeAe2xyz3wdoWlEL/oamGPcY10WW2Qzn1lWUYJWVjr85uDdgD7uoGs6Wage+Y3OJCUDBKgAtbsCQafhcwHIm1hb+4oIn5MEV0X7fuCf++KehsIkDXUqQ1sk0u+/tZbdnrcDusJho8yziAoHVOfSP/7LLU=;8FT4EJt0lwostZouQr42mA=="
---


---
category: news
title: "AI models make stuff up. How can hallucinations be controlled?"
excerpt: "In an AI model, such tendencies are usually described as hallucinations ... Consequently, says Dr Kamar, her research aims not to get rid of all hallucinations, but rather to stop the model from hallucinating when it would be unhelpful."
publishedDateTime: 2024-02-28T00:00:00Z
originalUrl: "https://www.economist.com/science-and-technology/2024/02/28/ai-models-make-stuff-up-how-can-hallucinations-be-controlled"
webUrl: "https://www.economist.com/science-and-technology/2024/02/28/ai-models-make-stuff-up-how-can-hallucinations-be-controlled"
type: article
quality: 39
heat: 39
published: false

provider:
  name: The Economist
  domain: economist.com

topics:
  - Meta AI
  - AI

images:
  - url: "https://www.economist.com/img/b/1280/720/90/media-assets/image/20240302_STD001.jpg"
    width: 1280
    height: 720
    isCached: true

secured: "ZtwZHrwd01x38QrHCyIoapMBlF/DSgVwHqPlSfN9pXu4tjy6tDfcK45OarvnshocFnzN9SPQAFpzTdVvAzI6YlNAEo1+ehek/eKT6Qh0bd6BV/k0+02dp+rjIWSYrgQ+pkxtR6n3A2FLgzH1EH2WalmiAKfcJVSJE5JO0rL92saSk5HcD7HgE94oDqOtJ4yBByU9GjRMKoNXgSMkirWCrgFEBOhMJNAm0nO+Rj5ezy+Wg6QLwt9Je06GikQkrpzTsif7mURdCO/F7VBBov/3/IOONpmKYSuBUFxo8wh6Ms6W2nnVXc7GMfN4/oKS4hCrqUqlS5NMOLmV5GwO1FgoMWuBIxoqjRYgS+2fCsqMyjY=;AJtK70SlIKLmyghq4kZQ3g=="
---


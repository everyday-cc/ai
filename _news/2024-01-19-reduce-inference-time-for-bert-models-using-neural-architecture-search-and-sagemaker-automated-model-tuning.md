---
category: news
title: "Reduce inference time for BERT models using neural architecture search and SageMaker Automated Model Tuning"
excerpt: "In this post, we demonstrate how to use neural architecture search (NAS) based structural pruning to compress a fine-tuned BERT model to improve model performance and reduce inference times. Pre-trained language models (PLMs) are undergoing rapid commercial and enterprise adoption in the areas of productivity"
publishedDateTime: 2024-01-19T18:06:10Z
originalUrl: "https://aws.amazon.com/blogs/machine-learning/reduce-inference-time-for-bert-models-using-neural-architecture-search-and-sagemaker-automated-model-tuning/"
webUrl: "https://aws.amazon.com/blogs/machine-learning/reduce-inference-time-for-bert-models-using-neural-architecture-search-and-sagemaker-automated-model-tuning/"
type: article
quality: 71
heat: 71
published: true

provider:
  name: AWS
  domain: aws.amazon.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/aws.amazon.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI
  - AWS AI

images:
  - url: "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2024/01/11/9-Comparison-Plot-1-803x630.png"
    width: 803
    height: 630
    isCached: true

secured: "/Ncy4wDnftsPnlNjv8IK0hIxmDDZNdZUKr9MycDTUNP9VlL3zu4RTZsUkuZyWmhNNlDmUYxtl155VO7dVupycR3sWV+3ORY/+lv5c+hM/e6Hhmn87QpIy3vG40YN1S8E+yOuYFKiQaV5HBSJczQeawcVVR3qBe+Q6wfWFJbYGqAYliyqdygf1BOURNuv7lxs92Y5F/daKtF2jh+xnltjUmUwc8ZOHCJYkVYP3ni/XScQaKd/0j234eAwpPGnzWcSQn8+tXBFtm8Ukm0DIClGfZZdNLQCf4EpWwEgAhg913H1CYX9A5luKGxgc4tbqzunn3cNA6Jo7CYyN/R0WRAr5OA1tXsI94U5zRjsJlmYP04=;1rywVRuvkcM3hhjtPNMhZw=="
---


---
category: news
title: "Training Compute-Optimal Large Language Models: DeepMind’s 70B Parameter Chinchilla Outperforms 530B Parameter Megatron-Turing"
excerpt: "Today’s extreme-scale language models have demonstrated astounding performance on natural language processing tasks, attributed mainly to their ever-expanding size, which can surpass 500 billion parameters."
publishedDateTime: 2022-04-04T16:50:00Z
originalUrl: "https://syncedreview.com/2022/04/04/training-compute-optimal-large-language-models-deepminds-70b-parameter-chinchilla-outperforms-530b-parameter-megatron-turing/"
webUrl: "https://syncedreview.com/2022/04/04/training-compute-optimal-large-language-models-deepminds-70b-parameter-chinchilla-outperforms-530b-parameter-megatron-turing/"
ampWebUrl: "https://syncedreview.com/2022/04/04/training-compute-optimal-large-language-models-deepminds-70b-parameter-chinchilla-outperforms-530b-parameter-megatron-turing/amp/"
cdnAmpWebUrl: "https://syncedreview-com.cdn.ampproject.org/c/s/syncedreview.com/2022/04/04/training-compute-optimal-large-language-models-deepminds-70b-parameter-chinchilla-outperforms-530b-parameter-megatron-turing/amp/"
type: article
quality: 48
heat: 48
published: false

provider:
  name: syncedreview
  domain: syncedreview.com

topics:
  - Google AI
  - AI
  - Natural Language Processing

images:
  - url: "https://i0.wp.com/syncedreview.com/wp-content/uploads/2022/04/image-6.png?fit=950%2C671&ssl=1"
    width: 950
    height: 671
    isCached: true

secured: "E8nnOC+AM8hkHG8Y1sPK5NG16U7uGtm3jwsxMFnm/oTOduysD7O41yeVyz9UYW7dAXiaSYz0nVlsH4lm/Ykk4bf+PJhgdStKOpsNT4ij5iHyiTOUEbn9dhux0Vanrd63p37+Gl/bEq10ZTYSrRPXMhRB02Y5Oo77TbMsnkMmfQ1ZDF5l0I45dT7wkZfmqenn2nrbixucBu9/FrfYq6WnInZzlsxhdmnhhB9Tf5XjWekewHP3qjMmij55BIjviBnkhRD+FKQfTQrVuCnJju7jv04d7bYqnJwDS/31l7pWwf6SrigGOgiKJi2dd4SNMKSqLC1tdTPbqBt3S7QI1rJoqKT34CMd+nAxlEydHOUduW0=;GYaKmZ2C5zODZy10Cc44ug=="
---


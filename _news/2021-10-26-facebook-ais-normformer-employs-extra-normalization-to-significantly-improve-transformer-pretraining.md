---
category: news
title: "Facebook AIâ€™s NormFormer Employs Extra Normalization to Significantly Improve Transformer Pretraining"
excerpt: "In a paper currently under review for ICLR 2022, a Facebook AI Research team introduces NormFormer, a modification to the Pre-LN transformer architecture designed to improve pretraining perplexity and downstream task performance for both causal and masked language models with negligible extra compute cost."
publishedDateTime: 2021-10-26T14:41:00Z
originalUrl: "https://syncedreview.com/2021/10/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-131/"
webUrl: "https://syncedreview.com/2021/10/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-131/"
ampWebUrl: "https://syncedreview.com/2021/10/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-131/amp/"
cdnAmpWebUrl: "https://syncedreview-com.cdn.ampproject.org/c/s/syncedreview.com/2021/10/26/deepmind-podracer-tpu-based-rl-frameworks-deliver-exceptional-performance-at-low-cost-131/amp/"
type: article
quality: 44
heat: 44
published: false

provider:
  name: syncedreview
  domain: syncedreview.com

topics:
  - Facebook AI
  - AI

images:
  - url: "https://i0.wp.com/syncedreview.com/wp-content/uploads/2021/10/image-78.png?fit=950%2C534&ssl=1"
    width: 949
    height: 534
    isCached: true

secured: "Rqqyd9kI714VlY6E2MUu9hps7PYXaUrPPQJKOkaQZCiFEkPE6dRlR2fezoVwv6X3L7G5kMkxUguBcOP736MOfWhTs+ByV7PxTFR5PnU+xbWr/RHYSqPw4xdWR4vKoUjeEmnlyjCLw++WbLWlIB0Co4WpIiJQjnDuGjZUCbymDsRnBoKmlmkI6MttdSG2TFVtC9DxL+31/E1p4XR0lNlIUVRKgihAdpjKd6ECWTl5gFUnyxy0U0fJbsZ1Zkcd8X7JgfiSM0i7tA8bdZhCUfVGErYWl7a4TeNjfgEObYbUPGUf9MEEK16hvIjecoSpIOY8Qhvukvc4/hpI9kLEOJSbh1mz3N4TMbJB1H5RYSAdI3o=;hIjA7cFFNERibKeuxoK6ow=="
---


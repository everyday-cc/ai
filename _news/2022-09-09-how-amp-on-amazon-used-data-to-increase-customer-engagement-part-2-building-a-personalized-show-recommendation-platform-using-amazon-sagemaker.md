---
category: news
title: "How Amp on Amazon used data to increase customer engagement, Part 2: Building a personalized show recommendation platform using Amazon SageMaker"
excerpt: "Amp is a new live radio app from Amazon. With Amp, you can host your own radio show and play songs from the Amazon Music catalog, or tune in and listen to shows other Amp users are hosting. In an environment where content is plentiful and diverse, it’s important to tailor the user experience to […]"
publishedDateTime: 2022-09-09T16:30:10Z
originalUrl: "https://aws.amazon.com/blogs/machine-learning/how-amp-on-amazon-used-data-to-increase-customer-engagement-part-2-building-a-personalized-show-recommendation-platform-using-amazon-sagemaker/"
webUrl: "https://aws.amazon.com/blogs/machine-learning/how-amp-on-amazon-used-data-to-increase-customer-engagement-part-2-building-a-personalized-show-recommendation-platform-using-amazon-sagemaker/"
type: article
quality: 52
heat: -1
published: false

provider:
  name: AWS
  domain: aws.amazon.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/aws.amazon.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI
  - AWS AI

images:
  - url: "https://d2908q01vomqb2.cloudfront.net/f1f836cb4ea6efb2a0b1b99f41ad8b103eff4b59/2022/09/09/amp-music-2.jpg"
    width: 1533
    height: 765
    isCached: true

related:
  - title: "How Medidata used Amazon SageMaker asynchronous inference to accelerate ML inference predictions up to 30 times faster"
    excerpt: "This post is co-written with Rajnish Jain, Priyanka Kulkarni and Daniel Johnson from Medidata. Medidata is leading the digital transformation of life sciences, creating hope for millions of patients. Medidata helps generate the evidence and insights to help pharmaceutical, biotech, medical devices, and"
    publishedDateTime: 2022-09-12T18:36:31Z
    webUrl: "https://aws.amazon.com/blogs/machine-learning/how-medidata-used-amazon-sagemaker-asynchronous-inference-to-accelerate-ml-inference-predictions-up-to-30-times-faster/"
    type: article
    provider:
      name: AWS
      domain: aws.amazon.com
    quality: 62
  - title: "Deploy large models on Amazon SageMaker using DJLServing and DeepSpeed model parallel inference"
    excerpt: "The last few years have seen rapid development in the field of natural language processing (NLP). Although hardware has improved, such as with the latest generation of accelerators from NVIDIA and Amazon, advanced machine learning (ML) practitioners still regularly encounter issues deploying their large"
    publishedDateTime: 2022-09-09T18:32:41Z
    webUrl: "https://aws.amazon.com/blogs/machine-learning/deploy-large-models-on-amazon-sagemaker-using-djlserving-and-deepspeed-model-parallel-inference/"
    type: article
    provider:
      name: AWS
      domain: aws.amazon.com
    quality: 57

secured: "OuaKs68FGH/FDpiGzm2mn6mS/hQC/aSM7pxLNr3T0uprLDn14/wgmcClG0s2wZiji7QKTHSC4Lg+OK1imTFkzuG3LCyNrGYjUc2et96IveWcmhF3Skhl5eomgVAdQv56gV9enuWaaP1KwWFF5VIhksLPVWI/CFj+nFqWMP1hugmexpb94bGFwL/0LZVvloGyPoKj/Frlwk6ZhC6bHcDXiLOAa9h2sDMXEzmCCPkFhHebMpGy/CQ7uPCLTsaZrAn8i/dfnKEicAN7EIXzJnp2NwD8lbkPQ7sc9jowxiak9g6DH39IZgDqa/wt+JC3sHYTjE2mjjbHeXXw5oCczJYxMqOVq3lHus881yc5JnryofE=;P9kAfZhUoOnj3Uw60uDp9Q=="
---


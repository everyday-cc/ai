---
category: news
title: "Researchers figure out how to make AI misbehave, serve up prohibited content"
excerpt: "Adversarial attacks exploit the way that machine learning picks up on patterns in data to produce aberrant behaviors. Imperceptible changes to images can, for instance, cause image classifiers to misidentify an object, or make speech recognition systems respond to inaudible messages."
publishedDateTime: 2023-08-02T13:22:00Z
originalUrl: "https://arstechnica.com/ai/2023/08/researchers-figure-out-how-to-make-ai-misbehave-serve-up-prohibited-content/2/?view=grid"
webUrl: "https://arstechnica.com/ai/2023/08/researchers-figure-out-how-to-make-ai-misbehave-serve-up-prohibited-content/2/?view=grid"
ampWebUrl: "https://arstechnica.com/ai/2023/08/researchers-figure-out-how-to-make-ai-misbehave-serve-up-prohibited-content/2/amp/"
cdnAmpWebUrl: "https://arstechnica-com.cdn.ampproject.org/c/s/arstechnica.com/ai/2023/08/researchers-figure-out-how-to-make-ai-misbehave-serve-up-prohibited-content/2/amp/"
type: article
quality: 66
heat: 66
published: false

provider:
  name: Ars Technica
  domain: arstechnica.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/arstechnica.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - Computer Vision
  - AI

secured: "Itm+wAjn+GwnE7vgvm5ATJS6jRPVX1rWoVBj+UcgqLPmxqCMYePDfHh3JNYHjWYkK5308sII2Yovh/TCKo47sCtn7jeWngpWPPsSb6N63i9fNw/ImA6FcWds1wR+CBgmCX7liGBPaBOPRwSezXP3XI1Acbhf/AReicQnhqxDA2nmJTsnsUbAHHAUhAqLEdeKMxH65mOAx1GINFDjve+8eBV2VombtqyJbx2JjSJRnoB8d3xdE5CAVlUeWc44Z0lT5fPKCgSySphQoB4SYhiBDPTkevC/jhG/J0VYu46svVTh8WcFZD3ZgrFRvLfeyqyKlaz65jc9ITfz6tt1jUZ1XMt55cCprQ6Jtw1/XbZyX6DY2GKLiOOitM4qNutEh/YGj2QyIhtuBn1r0OCiin46rMrvdrTVpONTNq+zWCjCIuDEuGqkzYPXstAFkxG6L5DNlHE9UfuaRqaPn/RM8/epNRJy9VL9TtZf78g/NfHjufyvwjeoxThXUSmlSIHdBCwQKDlLFs1jOvrx9lnZwWSh3Q==;c8m2f6VP8zS30/0fXg5V+g=="
---


---
category: news
title: "Running Llama 2 on Apple M3 Silicon Macs locally"
excerpt: "The latest Apple M3 Silicon chips provide huge amounts of processing power capable of running large language models like Llama 2 locally"
publishedDateTime: 2023-11-28T15:15:00Z
originalUrl: "https://www.geeky-gadgets.com/run-llama-2-on-apple-m3-macs-locally/"
webUrl: "https://www.geeky-gadgets.com/run-llama-2-on-apple-m3-macs-locally/"
type: article
quality: 26
heat: 26
published: false

provider:
  name: Geeky Gadgets
  domain: geeky-gadgets.com

topics:
  - Meta AI
  - AI
  - Natural Language Processing

images:
  - url: "https://www.geeky-gadgets.com/wp-content/uploads/2023/11/Running-Llama-2-on-Apple-M3-Silicon-hardware.jpg"
    width: 1280
    height: 716
    isCached: true

secured: "uDyTaWp5bBD2M+mA351BAaeSCBPO4NU9YYyNSV/YIKmEVGtvLdHBD6Q0hpOFXV8RBLJStB2WyWPkEnBYyf0vjrrQMP24zScP1oUfuTapLj3Yg/bUj33ylYn0LdnhP0RJo3T9Kn4d8hlX6MtX4h/oPC8XDuZsxplFB3hpaKDvLFR5i0aWb6edKkibxcB2+mP9l00P7WtqkFLL05pce2hZ+q8NCYhNgrObpp42a+WvizGKNpdvY6fUHCkM6WgyuH8Of6ho31nL/sw8XjjEQTZPJ2bDigC7aaMlN01b9GU8W8EDW4o23gvi0RZmISy30TgJunGcBANbEv5UeBtZCKh4g4OUoRk5el23DqSw/r02dxM=;SKek8Ro/8TjPKBKnQlPdXg=="
---


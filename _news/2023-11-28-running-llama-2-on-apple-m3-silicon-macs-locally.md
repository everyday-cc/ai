---
category: news
title: "Running Llama 2 on Apple M3 Silicon Macs locally"
excerpt: "The latest Apple M3 Silicon chips provide huge amounts of processing power capable of running large language models like Llama 2 locally"
publishedDateTime: 2023-11-28T15:15:00Z
originalUrl: "https://www.geeky-gadgets.com/run-llama-2-on-apple-m3-macs-locally/"
webUrl: "https://www.geeky-gadgets.com/run-llama-2-on-apple-m3-macs-locally/"
type: article
quality: 26
heat: 26
published: false

provider:
  name: Geeky Gadgets
  domain: geeky-gadgets.com

topics:
  - Meta AI
  - AI
  - Natural Language Processing

images:
  - url: "https://www.geeky-gadgets.com/wp-content/uploads/2023/11/Running-Llama-2-on-Apple-M3-Silicon-hardware.jpg"
    width: 1280
    height: 716
    isCached: true

secured: "+f4lA/mu/rczzHuYzL6JSycG9FuYUidn6C695ujhFItIO4o+Gso0gJKBlshaN/BStUj+Ja9xGBM/aPvqFPGoze3KA0H7ktTDMpGJ+9SudO4voRY2Nduaa2ciIXkZPuc7yJnlZDUg4TBJNB2VvakRq30pSAs0iOPWKPkdi2djCe8xin7xqKsXQ5lLpA0w+munYCcCxEI3Vhnspc45LKVUyMjlEuGQE/mA5HFWqqu2fVVvQ8o2vN6Yy9At3KeXcgQpqLD+bba4SJrTmxdOUDs0iyg75nF0+88d/jWPxAV9u4lxz/JhdihCq0Ay+FnhFvg+9rgo8J/cM0hVt8gCTR591GdRoFcCUDrKd+/buo3xrl+oIVhCrmCWLcBwiJ1mbSrPMO9hzOOSBHE78sBQ2UHYrI0/jiXgkfwicw5Hvu/7NIs35k55yrZNXg0MizI/KrFCS25nYBqqp7NqMj6yMHFw96SspqfmbIGS3ljn/LniSHREWN1i8SHbzbjwnBsAwv63zMRza5XUKok5JE3OOSGlQg==;xSMJiD3weYhfIr6bvXAnNw=="
---


---
category: news
title: "AI researchers say they've found 'virtually unlimited' ways to bypass Bard and ChatGPT's safety rules"
excerpt: "The researchers found they could use jailbreaks they'd developed for open-source systems to target mainstream and closed AI systems."
publishedDateTime: 2023-07-28T10:06:00Z
originalUrl: "https://www.businessinsider.com/ai-researchers-jailbreak-bard-chatgpt-safety-rules-2023-7"
webUrl: "https://www.businessinsider.com/ai-researchers-jailbreak-bard-chatgpt-safety-rules-2023-7"
ampWebUrl: "https://www.businessinsider.com/ai-researchers-jailbreak-bard-chatgpt-safety-rules-2023-7?amp"
cdnAmpWebUrl: "https://www-businessinsider-com.cdn.ampproject.org/c/s/www.businessinsider.com/ai-researchers-jailbreak-bard-chatgpt-safety-rules-2023-7?amp"
type: article
quality: 72
heat: 76
published: true

provider:
  name: Business Insider
  domain: businessinsider.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/businessinsider.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI

images:
  - url: "https://i.insider.com/64c38afe048ff200190c7baa?width=1200&format=jpeg"
    width: 1200
    height: 600
    isCached: true

secured: "KgLQLJWHrQ1R6VSpyBDGkdZwAUahHjHjLhMItQO8eMupuByMrByXOGh7GfAOC3WMPonclu55UG0RDGLQdHuPJmL37QE8TKGUinYsGisd7GXVWyZKEpsrd9QJI4fymEDULvtcHkW+Gd9VW5jpoMnAjRl57vJz0mkzMiS4/uy90WMjhexaJfyFGh5YuxsAO88TRkQmqjrwb0v80vh/BZRrjDYNGdtzjU3VmZVunDXJlY+j3LB72SL1THfddNHWAp/e8MMFS4lWVDASU1BX9t5PnYLGZtlT62vavXLoHVgQozj2l0SuUIeH6uZtdY9yHeK60v7J7CFjaO1n1xk8R2G+vafSkBldqbv22VyPCnR3qw7zVCVGCz9343MTz/CC1eJPmcE1w94CXhxeB8jqlARb4lRvhIvhVYJCg55a2QkJTshbleYXRfeaTHqXktQIB+ObGskJochpIvj45LoOLyU/avN2l0vzYslQUXOxP+wGkNDb3BkznwoXnrIybQxcwNHdDcLoGTcyBW7b/7JWFvkpAA==;bto8BmBilEi9ZuZ8sKpfvA=="
---


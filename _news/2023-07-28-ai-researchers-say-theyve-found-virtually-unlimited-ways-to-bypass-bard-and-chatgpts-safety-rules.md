---
category: news
title: "AI researchers say they've found 'virtually unlimited' ways to bypass Bard and ChatGPT's safety rules"
excerpt: "The researchers found they could use jailbreaks they'd developed for open-source systems to target mainstream and closed AI systems."
publishedDateTime: 2023-07-28T10:06:00Z
originalUrl: "https://www.businessinsider.com/ai-researchers-jailbreak-bard-chatgpt-safety-rules-2023-7"
webUrl: "https://www.businessinsider.com/ai-researchers-jailbreak-bard-chatgpt-safety-rules-2023-7"
ampWebUrl: "https://www.businessinsider.com/ai-researchers-jailbreak-bard-chatgpt-safety-rules-2023-7?amp"
cdnAmpWebUrl: "https://www-businessinsider-com.cdn.ampproject.org/c/s/www.businessinsider.com/ai-researchers-jailbreak-bard-chatgpt-safety-rules-2023-7?amp"
type: article
quality: 72
heat: 72
published: true

provider:
  name: Business Insider
  domain: businessinsider.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/businessinsider.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI

images:
  - url: "https://i.insider.com/64c38afe048ff200190c7baa?width=1200&format=jpeg"
    width: 1200
    height: 600
    isCached: true

secured: "vNyNOnh0v6AlQfi4MptWCpx0HGgIpUVZ6rjm9cSWKF9Jh8CchTctkvnLX//NaR0KAWhVXgTVCbZtQGY1swnutoeafe5a/5GZkjNDFcwARR6if8xymSRHrx5UCP9HM962MLS5O0wOAWiF7XcDAdIBFSyictauT9iFR+Qg18wRnv70W/DfmRtfOCKbM9EuVnNhNHXOMRdwaFtuf8OJ06acprt1+4TGLNBMli/TQ/KsOPHDj95/0RpeLRaenvvKuWyr7CSFe/5ABtcbg9nbsQs5FkT1LtJijE4au5wsVM1zBRjXukqhBx+YURsIVtjUwpuvs2jEVj7oFQKp2LXVJ8K/uj4G3asj1+cU6XgJJfPC+H4=;Ej5szsPSpnp9bHazlmtN8A=="
---


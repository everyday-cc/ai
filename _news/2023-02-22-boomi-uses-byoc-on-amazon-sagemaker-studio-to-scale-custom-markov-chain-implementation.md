---
category: news
title: "Boomi uses BYOC on Amazon SageMaker Studio to scale custom Markov chain implementation"
excerpt: "This post is co-written with Swagata Ashwani, Senior Data Scientist at Boomi. Boomi is an enterprise-level software as a service (SaaS) independent software vendor (ISV) that creates developer enablement tooling for software engineers. These tools integrate via API into Boomi’s core service offering."
publishedDateTime: 2023-02-22T21:04:28Z
originalUrl: "https://aws.amazon.com/blogs/machine-learning/boomi-uses-byoc-on-amazon-sagemaker-studio-to-scale-custom-markov-chain-implementation/"
webUrl: "https://aws.amazon.com/blogs/machine-learning/boomi-uses-byoc-on-amazon-sagemaker-studio-to-scale-custom-markov-chain-implementation/"
type: article
quality: 76
heat: -1
published: false

provider:
  name: AWS
  domain: aws.amazon.com
  images:
    - url: "https://everyday-cc.github.io/ai/assets/images/organizations/aws.amazon.com-50x50.jpg"
      width: 50
      height: 50

topics:
  - AI
  - AWS AI

related:
  - title: "Accelerate disaster response with computer vision for satellite imagery using Amazon SageMaker and Amazon Augmented AI"
    excerpt: "In this blog post we are discussing how to accelerate disaster response efforts using computer vision techniques for processing satellite imagery using AWS services."
    publishedDateTime: 2023-02-24T20:59:58Z
    webUrl: "https://aws.amazon.com/blogs/machine-learning/accelerate-disaster-response-with-computer-vision-for-satellite-imagery-using-amazon-sagemaker-and-amazon-augmented-ai/"
    type: article
    provider:
      name: AWS
      domain: aws.amazon.com
    quality: 77
  - title: "Achieve high performance at scale for model serving using Amazon SageMaker multi-model endpoints with GPU"
    excerpt: "Amazon SageMaker multi-model endpoints (MMEs) provide a scalable and cost-effective way to deploy a large number of machine learning (ML) models. It gives you the ability to deploy multiple ML models in a single serving container behind a single endpoint. From there, SageMaker manages loading and unloading"
    publishedDateTime: 2023-02-24T20:56:04Z
    webUrl: "https://aws.amazon.com/blogs/machine-learning/achieve-high-performance-at-scale-for-model-serving-using-amazon-sagemaker-multi-model-endpoints-with-gpu/"
    type: article
    provider:
      name: AWS
      domain: aws.amazon.com
    quality: 69
  - title: "MLOps deployment best practices for real-time inference model serving endpoints with Amazon SageMaker"
    excerpt: "After you build, train, and evaluate your machine learning (ML) model to ensure it’s solving the intended business problem proposed, you want to deploy that model to enable decision-making in business operations. Models that support business-critical functions are deployed to a production environment"
    publishedDateTime: 2023-02-21T19:28:58Z
    webUrl: "https://aws.amazon.com/blogs/machine-learning/mlops-deployment-best-practices-for-real-time-inference-model-serving-endpoints-with-amazon-sagemaker/"
    type: article
    provider:
      name: AWS
      domain: aws.amazon.com
    quality: 54

secured: "yW4yaDpzdvjoK+v8GgC7AYTj/55iyxNF943oP/WT5x2LUFNc0bR5YHVl7OmTLASIdWmGcgQmuFe+6LxykhiCWE/Nal3LmDCbqXnvWmU0NPaVUQOQWV8vjFkS00GwL7/DbHlGZujMZwYsjCxlpGCZKjruN9AvjeDFVAohPfnmudpDpb9FKx6eadcmnYF+cVdVQeNlQ15XUogThLM3ipuND2lSsyCrWtaD5t0jHhIoogbtBjVYg4JnsUe6HNjWl8Yds8d/vo5kCoUU8gde5V0tOxk1S9gaAwmMWgeeXpjoLWvNMwCuzHZppRoAUEkMQe4wDHyguXxnFh3tpdOfya2DORwCbNKJ7u3BzY0MQDTz3rM=;4xevNiFoBUf9QNgdXbt8Dg=="
---


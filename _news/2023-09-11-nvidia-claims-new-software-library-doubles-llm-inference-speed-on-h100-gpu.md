---
category: news
title: "Nvidia claims new software library doubles LLM inference speed on H100 GPU"
excerpt: "Nvidia plans to release an open-source software library that it claims will double the speed of inferencing large language models (LLMs) on its H100 GPUs. TensorRT-LLM will be integrated into Nvidia's NeMo LLM framework as part of the Nvidia AI Enterprise software suite early next month. It is currently available in early access."
publishedDateTime: 2023-09-10T19:48:00Z
originalUrl: "https://www.datacenterdynamics.com/en/news/nvidia-claims-new-software-library-doubles-llm-inference-speed-on-h100-gpu/"
webUrl: "https://www.datacenterdynamics.com/en/news/nvidia-claims-new-software-library-doubles-llm-inference-speed-on-h100-gpu/"
type: article
quality: 32
heat: -1
published: false

provider:
  name: Datacenter Dynamics
  domain: datacenterdynamics.com

topics:
  - AI Hardware
  - AI

related:
  - title: "Nvidia debuts new software to boost AI model performance on its high-end chips"
    excerpt: "Nvidia Corp. today announced a new open-source software suite called TensorRT-LLM that expands the capabilities of large language model optimizations on Nvidia graphics processing units and pushes the limits of artificial intelligence inference performance after deployment."
    publishedDateTime: 2023-09-08T18:02:00Z
    webUrl: "https://siliconangle.com/2023/09/08/nvidia-unveils-tensorrt-llm-boost-ai-inference-performance-h100-gpus/"
    type: article
    provider:
      name: SiliconANGLE
      domain: siliconangle.com
    quality: 50
    images:
      - url: "https://d15shllkswkct0.cloudfront.net/wp-content/blogs.dir/1/files/2023/04/nvidia-brand-logo-2-1920x1080.jpg"
        width: 1920
        height: 1080
        isCached: true
  - title: "TSMC Candidly Explains Why It Can't Keep Up With NVIDIA's Red Hot AI Chip Demand"
    excerpt: "Unlike many computing trends, AI has practical purposes, so it has stuck around beyond the initial fad period. People are using AI for anything and everything, even when it isn't particularly-suited for the task."
    publishedDateTime: 2023-09-08T18:52:00Z
    webUrl: "https://hothardware.com/news/why-tsmc-cant-keep-up"
    type: article
    provider:
      name: HotHardware
      domain: hothardware.com
    quality: 29
  - title: "Nvidia Says New Software Will Double LLM Inference Speed On H100 GPU"
    excerpt: "Nvidia said it plans to release open-source software that will significantly speed up inference performance for large language models powered by its GPUs, including the H100."
    publishedDateTime: 2023-09-08T18:42:00Z
    webUrl: "https://www.crn.com/news/components-peripherals/nvidia-says-new-software-will-double-llm-inference-speed-on-h100-gpu"
    type: article
    provider:
      name: CRN
      domain: crn.com
    quality: 19

secured: "DTahL9cdiaAPI06QDtyaPUVCTcjUZj7JvUoodtfES3Hb/ohXH8EbAgJemgQ2HlOF02s9GTDmYq98XrBGrAKcu7GyRQ5H23K3eQcCrV0yXZqSVj0gxp7vw41Y8KNU7Hfqnu8hBEiAZC0nG1JqakWsGFQSOUYMiQ0Hil34fgNMSohssaXOoNHXbDYkyi/L8Ei4DvXN/oDvdnikXbHWoylvUc7EU5YKspd4CQl3ypO8yROR6lUxMO0b/ZyKGTzd0LE54L9WG+vQSVob7HxjVqapIgrwEUYEWt9zrIBvt7motLVKb8uEleM/9T9obj+48vmkJ2e4MlmVb1q9uL/UDVSRY3cFVqRlApBtIJawRtqnzdgVd6rJJPZ1MS6zSxdsUP19ZmhgRmXGbjWkEhQSzTF02vgkp6w89nh2hrhAcF0Mampm5Mhqe0G0wF9J0g0pMvqWMgSqYXQmtzcPeu9RUXxbi94LQMA1F3YOf/VhLyxcBqdFOHK7pHqYVA/Dvg4BYt127Z33F16QV/56KbUPZsRHnw==;xCBe1g4+TqjGr1mt40GEPA=="
---

